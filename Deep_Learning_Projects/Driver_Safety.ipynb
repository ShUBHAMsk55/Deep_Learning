{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Safety Detector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following program performs a safety detection applications for the driver\n",
    "#### The program detection consists of :\n",
    "#####  1. Yawn Detection : In the 5 minutes of span if the driver yawns 3 or more times then the driver tiredness is alerted with the help of an alarm  \n",
    "#####  2.  Dizziness Detection: If the driver is feeling dizzy then an alarm is triggered                                                                                                             \n",
    "#####  3.  Phone usage detection : If the driver tries to use a cell phone while driving then  an alarm is triggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib \n",
    "import time\n",
    "import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yawn Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)      \n",
    "is_first = True\n",
    "first_time = 0.0\n",
    "counter = 0\n",
    "prev_time = 0.0\n",
    "alert_alarm = False\n",
    "\n",
    "while True:      \n",
    "    ret,frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "\n",
    "        \n",
    "        landmarks = predictor(gray,face)\n",
    "        \n",
    "        ul_y1_top = landmarks.part(50).y\n",
    "        ll_y1_bottom = landmarks.part(58).y\n",
    "        ul_y2_top = landmarks.part(52).y\n",
    "        ll_y2_bottom = landmarks.part(56).y\n",
    "                \n",
    "        if abs(ul_y1_top-ll_y1_bottom) and abs(ul_y2_top - ll_y2_bottom) > 34:\n",
    "            if is_first:\n",
    "                first_time = time.time()\n",
    "                is_first = False\n",
    "            elif is_first == False and  (time.time() - first_time) < 300 and (time.time() - prev_time) > 7:\n",
    "                prev_time = time.time()\n",
    "                counter += 1\n",
    "                \n",
    "                if counter == 3:\n",
    "                    is_first = True\n",
    "                    first_time = 0.0\n",
    "                    counter = 0\n",
    "                    prev_time = 0.0\n",
    "                    alert_alarm = True\n",
    "                    print('Alert')\n",
    "                    \n",
    "        \n",
    "    if alert_alarm == True:\n",
    "        alert_alarm = False\n",
    "        playsound.playsound('dataset/Alarm Alert Effect-SoundBible.com-462520910-[AudioTrimmer.com].mp3')\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "        \n",
    "capture.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dizziness Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)      \n",
    "status = True\n",
    "first_blink = 0.0\n",
    "alert_alarm = False\n",
    "\n",
    "while True:      \n",
    "    \n",
    "    ret,frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "        \n",
    "        landmarks = predictor(gray,face)\n",
    "        \n",
    "        le_y1_top = landmarks.part(37).y\n",
    "        le_y1_bottom = landmarks.part(41).y\n",
    "        le_y2_top = landmarks.part(38).y\n",
    "        le_y2_bottom = landmarks.part(40).y\n",
    "        \n",
    "        re_y1_top = landmarks.part(43).y\n",
    "        re_y1_bottom = landmarks.part(47).y\n",
    "        re_y2_top = landmarks.part(44).y\n",
    "        re_y2_bottom = landmarks.part(46).y\n",
    "        \n",
    "\n",
    "        if abs(le_y1_top-le_y1_bottom) and abs(le_y2_top-le_y2_bottom) and abs(re_y1_top-re_y1_bottom) and abs(re_y2_top-re_y2_bottom) < 5:\n",
    "            \n",
    "            if status == True:\n",
    "                first_blink = time.time()\n",
    "                status = False\n",
    "            \n",
    "            elif status == False and time.time() - first_blink > 4:\n",
    "                first_blink = 0.0\n",
    "                status = True\n",
    "                print('Alert')\n",
    "                \n",
    "    \n",
    "    \n",
    "    if alert_alarm == True:\n",
    "        alert_alarm = False\n",
    "        playsound.playsound('dataset/Alarm Alert Effect-SoundBible.com-462520910-[AudioTrimmer.com].mp3')\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "        \n",
    "capture.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Phone Usage Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights','yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open('coco.names','r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1 ] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = capture.read()\n",
    "    \n",
    "    \n",
    "    height,width,channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame,0.00392,(320,320),(0,0,0),True,crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    \n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            score = detection[5:]\n",
    "            class_id = np.argmax(score)\n",
    "            confidence = score[class_id]\n",
    "            if confidence > 0.3:\n",
    "                centre_x = int(detection[0] * width)\n",
    "                centre_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(centre_x - w/2)\n",
    "                y = int(centre_y - h/2)\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.3,0.3)\n",
    "\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            if label == 'cell phone':\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                playsound.playsound('dataset/Alarm Alert Effect-SoundBible.com-462520910-[AudioTrimmer.com].mp3')\n",
    "            \n",
    "    cv2.imshow('Image',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
